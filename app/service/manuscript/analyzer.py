import json
import time
from typing import List, Dict, Any, Set

# LangChain & AI ê´€ë ¨
from langchain_upstage import ChatUpstage
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.utilities import GoogleSerperAPIWrapper

# ë¡œì»¬ DB ë ˆí¬ì§€í† ë¦¬
from app.service.manuscript.repo import ManuscriptRepository

class ManuscriptAnalyzer:
    def __init__(self, setting_path: str):
        # 1. LLM ì„¤ì • (Solar-pro)
        self.llm = ChatUpstage(model="solar-pro")

        # 2. ì†Œì„¤ ì„¤ì •(Plot DB) ë¡œë“œ -> í—ˆêµ¬ ì •ë³´ í•„í„°ë§ìš©
        self.settings = self._load_settings(setting_path)
        self.setting_keywords = self._extract_setting_keywords()

        # 3. ë¡œì»¬ ë²¡í„° DB (ê¸°ì¡´ ì§€ì‹)
        self.repo = ManuscriptRepository()

        # 4. Web Search ë„êµ¬ (Serper)
        # gl='kr': í•œêµ­ êµ¬ê¸€, hl='ko': í•œêµ­ì–´ ì¸í„°í˜ì´ìŠ¤ (í•„ìš”ì‹œ 'en'ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)
        self.search_tool = GoogleSerperAPIWrapper(gl='kr', hl='ko')

        # 5. í…ìŠ¤íŠ¸ ë¶„í• ê¸°
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " ", ""]
        )

    def _load_settings(self, path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼(JSON)ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
            return {}

    def _extract_setting_keywords(self) -> Set[str]:
        """ì†Œì„¤ ì† í—ˆêµ¬ì˜ ê³ ìœ ëª…ì‚¬(ë“±ì¥ì¸ë¬¼, ì§€ëª… ë“±)ë¥¼ Setìœ¼ë¡œ ì¶”ì¶œ"""
        keywords = set()
        data = self.settings

        # ë“±ì¥ì¸ë¬¼ ì´ë¦„
        for char in data.get("characters", []):
            name = char.get("name", "").strip()
            if name: keywords.add(name)

        # ì„¸ë ¥/ë‹¨ì²´ëª…
        factions = data.get("world_view", {}).get("factions", [])
        for f in factions:
            if isinstance(f, str):
                keywords.add(f.split("(")[0].strip())

        # (ì„ì‹œ) í…ŒìŠ¤íŠ¸ìš© í—ˆêµ¬ í‚¤ì›Œë“œ ì¶”ê°€
        keywords.add("ì—ì´ë‹¨")
        keywords.add("ì—ì´ë‹¨ ì‹ ë¶€")

        return keywords

    def analyze_manuscript(self, text: str) -> Dict[str, Any]:
        """
        [ë©”ì¸ ë¡œì§]
        1. í…ìŠ¤íŠ¸ ë¶„í• 
        2. 'ê²€ìƒ‰ ì¿¼ë¦¬' ìƒì„± (ë‹¨ìˆœ í‚¤ì›Œë“œ ì¶”ì¶œ X)
        3. í•„í„°ë§ (ì„¤ì • DB í™•ì¸)
        4. ë¡œì»¬ DB ì¡°íšŒ -> ì›¹ ê²€ìƒ‰ -> ê²°ê³¼ ê²€ì¦
        """
        print(f"ğŸ“„ ì›ê³  ë¶„ì„ ì‹œì‘ (ì´ {len(text)}ì)")
        chunks = self.text_splitter.split_text(text)

        # 1. ì²­í¬ë³„ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ í›„ë³´ ì¶”ì¶œ
        all_query_items = {} # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ Dict ì‚¬ìš© {keyword: query_info}

        for i, chunk in enumerate(chunks):
            items = self._extract_search_queries(chunk)
            for item in items:
                kw = item['keyword']
                # ì´ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë©´ ë®ì–´ì“°ê±°ë‚˜ ë¬´ì‹œ (ì—¬ê¸°ì„  ìµœì‹  ì¿¼ë¦¬ë¡œ ê°±ì‹ )
                all_query_items[kw] = item

        print(f"   -> ì´ {len(all_query_items)}ê°œì˜ ê²€ìƒ‰ í›„ë³´ ì¶”ì¶œë¨")

        known_settings = []     # ì†Œì„¤ ì„¤ì •ì— ìˆëŠ” ë‹¨ì–´ (ê²€ìƒ‰ ì•ˆ í•¨)
        historical_context = [] # ìµœì¢… ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        # 2. í›„ë³´êµ° ìˆœíšŒ ë° ì²˜ë¦¬
        for keyword, item_data in all_query_items.items():
            query_string = item_data['search_query']
            reason = item_data.get('reason', '')

            # [Filter 1] ì†Œì„¤ ì„¤ì •(í—ˆêµ¬)ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            # ë‹¨ìˆœ ì¼ì¹˜ë¿ë§Œ ì•„ë‹ˆë¼ ë¶€ë¶„ ì¼ì¹˜ë„ ì²´í¬ (ì˜ˆ: 'ì—ì´ë‹¨' in 'ì—ì´ë‹¨ ì‹ ë¶€ë‹˜')
            is_fiction = False
            for fiction_term in self.setting_keywords:
                if fiction_term in keyword or keyword in fiction_term:
                    is_fiction = True
                    break

            if is_fiction:
                known_settings.append(keyword)
                continue # ê²€ìƒ‰ ìŠ¤í‚µ

            # [Process] ì •ë³´ ê²€ìƒ‰ ì‹œì‘
            print(f"ğŸ” ë¶„ì„ ì¤‘: '{keyword}' (Query: {query_string})")

            # Step A: ë¡œì»¬ DB í™•ì¸ (Vector Store)
            local_result = self._check_local_db(keyword)
            if local_result:
                print(f"   âœ… ë¡œì»¬ DB ë°œê²¬")
                historical_context.append(local_result)
                continue # ë¡œì»¬ì— ìˆìœ¼ë©´ ì›¹ ê²€ìƒ‰ ìŠ¤í‚µ

            # Step B: ì›¹ ê²€ìƒ‰ (Serper)
            web_data = self._search_web(query_string)
            if web_data:
                # Step C: [NEW] ê²€ìƒ‰ ê²°ê³¼ ì í•©ì„± ê²€ì¦ (LLM)
                # ê²€ìƒ‰ëœ ë‚´ìš©ì´ ì‹¤ì œ ì†Œì„¤ì˜ ì‹œëŒ€ì  ë°°ê²½/ë§¥ë½ê³¼ ë§ëŠ”ì§€ í™•ì¸
                verification = self._verify_content_relevance(keyword, query_string, web_data['content'])

                if verification['is_relevant']:
                    web_data['verification_note'] = verification['reason']
                    historical_context.append(web_data)
                    print(f"   ğŸŒ ì›¹ ê²€ìƒ‰ ì„±ê³µ & ê²€ì¦ í†µê³¼")
                else:
                    print(f"   ğŸ—‘ï¸ ê²€ì¦ íƒˆë½: {verification['reason']}")
            else:
                print(f"   âŒ ì •ë³´ ì—†ìŒ")

            time.sleep(0.5) # API ì†ë„ ì¡°ì ˆ

        return {
            "found_entities_count": len(all_query_items),
            "setting_terms_found": list(set(known_settings)), # ì¤‘ë³µ ì œê±°
            "historical_context": historical_context
        }

    def _extract_search_queries(self, text: str) -> List[Dict[str, str]]:
        """
        [ìˆ˜ì •ë¨] êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ì œê±°í•˜ê³  ë…¼ë¦¬ì  ì§€ì‹œë§Œ ë‚¨ê¸´ ì¿¼ë¦¬ ìƒì„±ê¸°
        """
        prompt = """
        ë‹¹ì‹ ì€ ì—­ì‚¬ ì†Œì„¤ ê³ ì¦ì„ ìœ„í•œ 'ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±ê¸°'ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì½ê³ , ì—­ì‚¬ì  ì‚¬ì‹¤ í™•ì¸ì´ í•„ìš”í•œ í•­ëª©ì„ ì°¾ì•„ **êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´**ë¡œ ë³€í™˜í•˜ì„¸ìš”.

        [ì‘ì—… ê·œì¹™]
        1. **ëŒ€ìƒ:** ì‹¤ì¡´ ì¸ë¬¼, ì§€ëª…, ì‚¬ê±´, ìœ ë¬¼, ë‹¹ì‹œì˜ ë¬¸í™”/ì œë„.
        2. **ì œì™¸(Strict):** - 'ì˜ê³¼ ëŒ€í•™', 'ë³‘ì›', 'ì‹ ë¶€ë‹˜', 'ë§ˆì°¨' ê°™ì€ **ìˆ˜ì‹ì–´ ì—†ëŠ” ì¼ë°˜ ëª…ì‚¬ ì ˆëŒ€ ì œì™¸**.
           - '19ì„¸ê¸°', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ëŸ°ë˜ì˜ ê±°ë¦¬' ê°™ì€ **ë‹¨ìˆœ ì‹œê³µê°„ ë¬˜ì‚¬ ì œì™¸**.
           - ì£¼ì¸ê³µì˜ ì‚¬ì ì¸ í–‰ë™, ê°ì • ë¬˜ì‚¬, ëŒ€í™”ì˜ ì¼ìƒì ì¸ ì†Œì¬ ì œì™¸.
        3. **ì¿¼ë¦¬ ìµœì í™” ì§€ì¹¨:** - ë‹¨ìˆœíˆ ë³¸ë¬¸ì˜ ë‹¨ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ê³ , **ê²€ìƒ‰ ì—”ì§„ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœ**ë¡œ ì¡°í•©í•˜ì„¸ìš”.
           - ì¸ë¬¼ ì´ë¦„ì´ ë¶ˆì™„ì „í•˜ê²Œ ë‚˜ì˜¤ë©´(ì˜ˆ: ì„±ë§Œ ë‚˜ì˜¤ê±°ë‚˜ ì´ë¦„ë§Œ ë‚˜ì˜¬ ë•Œ), ë¬¸ë§¥ì„ íŒŒì•…í•´ **ì „ì²´ ì´ë¦„ì´ë‚˜ ì§ì—…**ì„ ë§ë¶™ì´ì„¸ìš”.
           - ì§€ëª…ì´ë‚˜ ê³ ìœ ëª…ì‚¬ê°€ ëª¨í˜¸í•  ê²½ìš°, **'ì—­ì‚¬', 'ìœ ë˜', '19ì„¸ê¸°' ë“±ì˜ í‚¤ì›Œë“œ**ë¥¼ ì¿¼ë¦¬ì— í¬í•¨ì‹œì¼œ ë²”ìœ„ë¥¼ ì¢íˆì„¸ìš”.

        [ì¶œë ¥ í˜•ì‹]
        ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ **JSON ë¦¬ìŠ¤íŠ¸**ë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ë§ˆí¬ë‹¤ìš´ ì—†ì´)
        [
            {"keyword": "ë³¸ë¬¸ì— ë‚˜ì˜¨ ì›ë³¸ ë‹¨ì–´", "search_query": "ìµœì í™”ëœ êµ¬ê¸€ ê²€ìƒ‰ìš© ì¿¼ë¦¬", "reason": "ê²€ìƒ‰ì´ í•„ìš”í•œ ì´ìœ  ìš”ì•½"}
        ]
        """

        try:
            response = self.llm.invoke([
                SystemMessage(content=prompt),
                HumanMessage(content=f"Text: {text[:3000]}")
            ])
            content = response.content.strip()

            # JSON íŒŒì‹±
            return self._parse_json_garbage(content)

        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ ìƒì„± ì—ëŸ¬: {e}")
            return []

    def _check_local_db(self, keyword: str) -> Dict[str, Any]:
        """ë¡œì»¬ ë²¡í„° DB ì¡°íšŒ"""
        try:
            # ê²€ìƒ‰
            search_result = self.repo.search(query_text=keyword, n_results=1)

            if not search_result['documents'][0]:
                return None

            dist = search_result['distances'][0][0]
            content = search_result['documents'][0][0]

            # ê±°ë¦¬ ì„ê³„ê°’ (1.2ë³´ë‹¤ ê°€ê¹Œì›Œì•¼ ê´€ë ¨ì„± ìˆìŒ)
            if dist < 1.2:
                return {
                    "keyword": keyword,
                    "content": content,
                    "source": "Local History DB",
                    "confidence": round(1 - (dist/2), 2)
                }
            return None
        except Exception:
            return None

    def _search_web(self, query: str) -> Dict[str, Any]:
        """Serper ì›¹ ê²€ìƒ‰"""
        try:
            # ê²€ìƒ‰ì–´ì— 'ì—­ì‚¬' í‚¤ì›Œë“œê°€ ì—†ë‹¤ë©´ ì¶”ê°€ (ì˜ì–´/í•œê¸€ í˜¼ìš©)
            if "ì—­ì‚¬" not in query and "history" not in query.lower():
                final_query = f"{query} ì—­ì‚¬ history"
            else:
                final_query = query

            result_text = self.search_tool.run(final_query)

            if not result_text or len(result_text) < 10:
                return None

            return {
                "keyword": query, # ê²€ìƒ‰ì— ì“´ ì¿¼ë¦¬ ì €ì¥
                "content": result_text,
                "source": "Web Search (Serper)"
            }
        except Exception:
            return None

    def _verify_content_relevance(self, keyword: str, query: str, content: str) -> Dict[str, Any]:
        """
        [NEW] ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ê¸°
        ì°¾ì•„ì˜¨ ì •ë³´ê°€ ë‚´ê°€ ì˜ë„í•œ ë§¥ë½(ì—­ì‚¬ì  ì‚¬ì‹¤)ê³¼ ë§ëŠ”ì§€ LLMì´ íŒë³„í•©ë‹ˆë‹¤.
        ì˜ˆ: 'ì—…í„´' ê²€ìƒ‰ ê²°ê³¼ê°€ 'ì¼€ì´íŠ¸ ì—…í„´(ëª¨ë¸)'ì´ë©´ False ë°˜í™˜.
        """
        prompt = f"""
        ë‹¹ì‹ ì€ ì—­ì‚¬ ìë£Œ ê²€ì¦ê´€ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ '{keyword}'(ì¿¼ë¦¬: {query})ë¥¼ ê²€ìƒ‰í–ˆê³ , ì•„ë˜ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.
        ì´ ê²°ê³¼ê°€ **ì—­ì‚¬ì  ì‚¬ì‹¤, ì§€ë¦¬, ì¸ë¬¼ ì •ë³´**ë¡œì„œ ìœ ì˜ë¯¸í•œì§€ íŒë‹¨í•˜ì„¸ìš”.

        [ê²€ìƒ‰ ê²°ê³¼]
        {content[:1000]}

        [íŒë‹¨ ê¸°ì¤€]
        1. **ë¶€ì í•©:** í˜„ëŒ€ì˜ ì—°ì˜ˆì¸(ëª¨ë¸, ë°°ìš°), ì‡¼í•‘ëª°, ë‹¨ìˆœ ì‚¬ì „ì  ì •ì˜, ê²Œì„/ì˜í™” ì •ë³´.
        2. **ì í•©:** ì—­ì‚¬ì  ì¸ë¬¼, ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì§€ëª…, ì—­ì‚¬ì  ì‚¬ê±´, ê¸°ê´€ì˜ ì—°í˜.

        ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
        {{
            "is_relevant": true/false,
            "reason": "íŒë‹¨ ì´ìœ  í•œ ë¬¸ì¥"
        }}
        """
        try:
            response = self.llm.invoke([SystemMessage(content=prompt)])
            return self._clean_json_string(response.content)
        except:
            # ì—ëŸ¬ ë‚˜ë©´ ì¼ë‹¨ í†µê³¼ (False Negative ë°©ì§€)
            return {"is_relevant": True, "reason": "ê²€ì¦ ì‹¤íŒ¨(Pass)"}

    def _parse_json_garbage(self, text: str) -> List[Dict]:
        """LLMì´ ì£¼ëŠ” ì§€ì €ë¶„í•œ JSON ë¬¸ìì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
        try:
            # ë§ˆí¬ë‹¤ìš´ ì œê±°
            text = text.replace("```json", "").replace("```", "").strip()

            # ê°€ì¥ ë°”ê¹¥ìª½ ëŒ€ê´„í˜¸ ì°¾ê¸°
            start = text.find('[')
            end = text.rfind(']')
            if start != -1 and end != -1:
                json_str = text[start:end+1]
                return json.loads(json_str)
            return []
        except:
            return []

    def _clean_json_string(self, text: str) -> str:
        """
                [ìˆ˜ì •ë¨] ì…ë ¥ì´ ì´ë¯¸ Dictë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ê³ ,
                Stringì´ë¼ë©´ JSON êµ¬ê°„ë§Œ ì¶”ì¶œí•˜ì—¬ íŒŒì‹±í•©ë‹ˆë‹¤.
                (TypeError ë°©ì§€ìš© ë°©ì–´ ì½”ë“œ í¬í•¨)
                """
        # 1. ì…ë ¥ì´ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬(Dict)ë¼ë©´ íŒŒì‹±í•  í•„ìš” ì—†ì´ ë°”ë¡œ ë°˜í™˜
        if isinstance(text, dict):
            return text

        # 2. ë¬¸ìì—´ì´ ì•„ë‹ˆë¼ë©´(None ë“±) ë¹ˆ Dict ë°˜í™˜
        if not isinstance(text, str):
            return {}

        try:
            # 3. ë§ˆí¬ë‹¤ìš´ ë° ê³µë°± ì œê±°
            text = text.replace("```json", "").replace("```", "").strip()

            # 4. ê°€ì¥ ë°”ê¹¥ìª½ {} ì°¾ê¸° (ì‚¬ì¡± ì œê±°)
            start_idx = text.find('{')
            end_idx = text.rfind('}')

            if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                json_str = text[start_idx : end_idx + 1]
                return json.loads(json_str)

            # 5. ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ íŒŒì‹± ì‹œë„
            return json.loads(text)

        except Exception:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
            return {}