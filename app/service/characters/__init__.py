# app/service/characters/__init__.py
from __future__ import annotations

import json
import os
import re
from typing import Any, Dict, List, Tuple

DB_PATH = "app/data/characters.json"

from app.service.characters.solar_client import SolarClient

# -------------------------
# íŒŒì¼ IO
# -------------------------
def _read_json_safe(path: str) -> Dict[str, Any]:
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data if isinstance(data, dict) else {}
    except Exception:
        return {}


def _write_json(path: str, data: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


# -------------------------
# í…ìŠ¤íŠ¸ ìœ í‹¸
# -------------------------
def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def _clean_value(v: str) -> str:
    v = _norm(v)
    return v if v else "none"


def _strip_bullet(line: str) -> str:
    line = line.strip()
    line = re.sub(r"^[\-\*\â€¢]\s*", "", line)
    line = re.sub(r"^\d+[\.\)]\s*", "", line)
    return line.strip()


def _split_bullets(block: str) -> List[str]:
    if not block:
        return []
    lines = [x.strip() for x in block.splitlines() if x.strip()]
    out: List[str] = []
    for ln in lines:
        ln = _strip_bullet(ln)
        if ln:
            out.append(ln)
    return out


def _remove_footnotes(text: str) -> str:
    return re.sub(r"\[\d+\]", "", text)


def _clean_name(name: str) -> str:
    name = _remove_footnotes(name)
    name = re.sub(r"[\(\)ã€ã€‘\[\]]", "", name).strip()
    name = re.sub(r"\s+", " ", name).strip()
    return name


# -------------------------
# ì–‘ì‹í˜• ì„¹ì…˜ íŒŒì‹±
# -------------------------
SECTION_ALIASES = {
    "age_gender": ["ë‚˜ì´(ìƒë…„ì›”ì¼, ì—†ìœ¼ë©´ ë‚˜ì´ë§Œ) /ì„±ë³„", "ë‚˜ì´/ì„±ë³„", "ë‚˜ì´", "ìƒë…„ì›”ì¼", "ì„±ë³„"],
    "job_status": ["ì§ì—…/ì‹ ë¶„", "ì§ì—…", "ì‹ ë¶„"],
    "core_traits": ["í•µì‹¬ íŠ¹ì§•", "í•µì‹¬íŠ¹ì§•", "íŠ¹ì§•"],
    "personality": ["ì„±ê²©"],
    "outer_goal": ["ì™¸ì  ëª©í‘œ"],
    "inner_goal": ["ë‚´ì  ëª©í‘œ"],
    "trauma_weakness": ["íŠ¸ë¼ìš°ë§ˆ/ì•½ì ", "íŠ¸ë¼ìš°ë§ˆ", "ì•½ì "],
    "speech_habit": ["ë§ë²„ë¦‡ì´ë‚˜ ìŠµê´€", "ë§ë²„ë¦‡", "ìŠµê´€"],
    "relationships": ["ë‹¤ë¥¸ ì£¼ìš” ì¸ë¬¼ê³¼ì˜ ê´€ê³„", "ì£¼ìš” ì¸ë¬¼ê³¼ì˜ ê´€ê³„", "ê´€ê³„"],
}


def _detect_section(line: str) -> Tuple[str | None, str]:
    s = line.strip()
    s_no_paren = re.sub(r"\(.*?\)", "", s).strip()

    for key, aliases in SECTION_ALIASES.items():
        for a in aliases:
            if s_no_paren.startswith(a):
                if ":" in s:
                    return key, s.split(":", 1)[1].strip()
                rest = s_no_paren[len(a):].strip()
                rest = rest.lstrip("-").strip()
                return key, rest
    return None, ""


def _collect_sections(text: str) -> Dict[str, str]:
    lines = [ln.rstrip() for ln in (text or "").splitlines()]
    lines = [ln for ln in lines if ln.strip()]

    buckets: Dict[str, List[str]] = {k: [] for k in SECTION_ALIASES.keys()}
    current: str | None = None

    for ln in lines:
        key, inline = _detect_section(ln)
        if key:
            current = key
            if inline:
                buckets[current].append(inline)
            continue
        if current:
            buckets[current].append(ln.strip())

    return {k: "\n".join(v).strip() for k, v in buckets.items()}


def _parse_personality(block: str) -> Dict[str, Any]:
    if not block:
        return {"pros": "none", "cons": "none"}

    lines = [x.strip() for x in block.splitlines() if x.strip()]
    mode = None
    pros: List[str] = []
    cons: List[str] = []
    misc: List[str] = []

    for ln in lines:
        s = _strip_bullet(ln)
        if not s:
            continue

        if s.startswith("ì¥ì "):
            mode = "pros"
            after = s.split(":", 1)[1].strip() if ":" in s else s.replace("ì¥ì ", "", 1).strip()
            if after:
                pros.extend(_split_bullets(after))
            continue

        if s.startswith("ë‹¨ì "):
            mode = "cons"
            after = s.split(":", 1)[1].strip() if ":" in s else s.replace("ë‹¨ì ", "", 1).strip()
            if after:
                cons.extend(_split_bullets(after))
            continue

        if mode == "pros":
            pros.append(s)
        elif mode == "cons":
            cons.append(s)
        else:
            misc.append(s)

    if (not pros and not cons) and misc:
        items = _split_bullets("\n".join(misc))
        pros = items[:3]
        cons = items[3:6]

    return {
        "pros": pros[:3] if pros else "none",
        "cons": cons[:3] if cons else "none",
    }


# -------------------------
# ì„œìˆ í˜• ì¶”ì¶œ
# -------------------------
def _extract_job_status(text: str) -> str:
    candidates: List[str] = []
    keywords = [
        "ì™¸ìƒì™¸ê³¼ì˜", "ì™¸ê³¼ì˜", "ì¼ë°˜ì™¸ê³¼", "ì˜ì‚¬", "ì „ì„ ì¡°êµìˆ˜", "ì¡°êµìˆ˜", "êµìˆ˜", "êµ°ì˜ê´€",
        "ì˜ëŒ€", "UCL", "ë©´í—ˆ", "ëŸ°ë˜ëŒ€ êµìˆ˜",
    ]
    for kw in keywords:
        if kw in text:
            candidates.append(kw)

    uniq: List[str] = []
    for x in candidates:
        if x not in uniq:
            uniq.append(x)

    if not uniq:
        return "none"
    return ", ".join(uniq[:5])


def _extract_trauma_weakness(text: str) -> str:
    if "ë‡Œì¢…ì–‘" in text and "íŒì •" in text:
        return "ë‡Œì¢…ì–‘ íŒì • ê²½í—˜"
    if "ê²°í•µ" in text:
        return "ì „ìŸ ì¤‘ ê²°í•µìœ¼ë¡œ ì£½ì„ ë»”í•¨"
    if "ì£½ì„ ë»”" in text:
        return "ìƒëª… ìœ„í˜‘ ê²½í—˜"
    return "none"


def _extract_speech_habit(text: str) -> str:
    if "ì¡°ì„  ì˜í•™" in text and ("ê±°ì§“ë§" in text or "êµ¬ë¼" in text):
        return "í˜„ëŒ€ì§€ì‹ ì¶œì²˜ë¥¼ 'ì¡°ì„  ì˜í•™'ì´ë¼ê³  ë‘˜ëŸ¬ëŒ€ëŠ” ìŠµê´€"
    return "none"


def _extract_core_traits(text: str) -> List[str] | str:
    traits: List[str] = []

    if "21ì„¸ê¸°" in text and "19ì„¸ê¸°" in text and ("ë‹¤ì‹œ íƒœì–´ë‚œë‹¤" in text or "í™˜ìƒ" in text):
        traits.append("21ì„¸ê¸° í•œêµ­ ì¶œì‹ ìœ¼ë¡œ 19ì„¸ê¸° ì˜êµ­ì—ì„œ ì¡°ì„ ì¸ìœ¼ë¡œ ë‹¤ì‹œ íƒœì–´ë‚¨")

    if "ì™¸ìƒì™¸ê³¼" in text or "ì¼ë°˜ì™¸ê³¼" in text or "ì™¸ê³¼ì˜" in text:
        traits.append("í˜„ëŒ€ ì™¸ê³¼(ì¼ë°˜/ì™¸ìƒ) ì „ë¬¸ ì§€ì‹ê³¼ ìˆ˜ìˆ  ì‹¤ë ¥ ë³´ìœ ")

    if "ì¡°ì„  ì˜í•™" in text and ("ê±°ì§“ë§" in text or "êµ¬ë¼" in text):
        traits.append("í˜„ëŒ€ ì§€ì‹ ì‚¬ìš© ì‹œ 'ì¡°ì„  ì˜í•™ì—ì„œ ë°°ì› ë‹¤'ê³  ìœ„ì¥")

    if "êµ°ì˜ê´€" in text or "ì°¸ì „" in text or "ì „ìŸ" in text:
        traits.append("ì „ìŸì— êµ°ì˜ê´€ìœ¼ë¡œ ì°¸ì—¬í•˜ë©° ì¹˜ë£Œ/ì„ìƒ ê²½í—˜ ì¶•ì ")

    uniq: List[str] = []
    for t in traits:
        if t not in uniq:
            uniq.append(t)

    return uniq if uniq else "none"


def _extract_relationships(text: str) -> List[str] | str:
    rels: List[str] = []

    if "ë¦¬ìŠ¤í„´" in text:
        if "ì¶”ì²œ" in text:
            rels.append("ë¡œë²„íŠ¸ ë¦¬ìŠ¤í„´: ê°•ë ¥ ì¶”ì²œ/ë™ë£Œ(í˜¹ì€ ìŠ¤ìŠ¹ê¸‰ ì¸ë§¥)")
        else:
            rels.append("ë¦¬ìŠ¤í„´: ë™ë£Œ/í˜‘ì—… ì¸ë¬¼(ë³¸ë¬¸ ê¸°ë°˜)")
    if "ë‚˜ì´íŒ…ê²Œì¼" in text:
        rels.append("ë‚˜ì´íŒ…ê²Œì¼: í¬ë¦¼ ì „ìŸ ì•¼ì „ë³‘ì› ì²´ê³„ êµ¬ì¶• í˜‘ì—…")
    if "í›„ì›" in text or "ì§€ì—­ ìœ ì§€" in text:
        rels.append("ì§€ì—­ ìœ ì§€: ì¸ì¢…ì°¨ë³„ ì‹œëŒ€ì— í›„ì›ì")

    uniq: List[str] = []
    for r in rels:
        if r not in uniq:
            uniq.append(r)

    return uniq if uniq else "none"


def _extract_goals(text: str) -> Tuple[str, str]:
    outer = "none"
    inner = "none"
    if "ë§ì—°ìì‹¤" in text or "ë‡Œì¢…ì–‘" in text:
        inner = "ì£½ìŒ/ì§ˆë³‘ ê²½í—˜ ì´í›„ ìƒì¡´ê³¼ ì„±ì¥ì— ì§‘ì°©í•˜ê²Œ ë¨(ì„œìˆ  ê¸°ë°˜)"
    return outer, inner


def _extract_age_gender(text: str) -> str:
    # ë‚˜ì´: 21ì„¸ê¸° ê°™ì€ ê±´ ì œì™¸
    age = ""
    gender = ""

    m_age = re.search(r"(\d{1,3})\s*ì„¸(?!ê¸°)", text)
    if m_age:
        age = f"{m_age.group(1)}ì„¸"

    # ì„±ë³„ì€ ë‚¨/ì—¬ í•œ ê¸€ì ì˜¤íƒ ë§ì•„ì„œ ì œì™¸
    m_gender = re.search(r"(ë‚¨ì|ì—¬ì|ë‚¨ì„±|ì—¬ì„±)", text)
    if m_gender:
        g = m_gender.group(1)
        gender = "ë‚¨ì" if g in ("ë‚¨ì", "ë‚¨ì„±") else "ì—¬ì"

    if not age and not gender:
        return "none"
    if age and gender:
        return f"{age} / {gender}"
    return age or gender

def _extract_from_text(text: str) -> Dict[str, Any]:
    print("\n" + "="*50)
    print("ğŸš€ [1ë‹¨ê³„] _extract_from_text ì‹œì‘")
    print(f"   ğŸ‘‰ ì…ë ¥ëœ í…ìŠ¤íŠ¸(ì• 50ì): {text[:50]}...")

    if not text or not text.strip():
        print("   âš ï¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì–´ì„œ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë¦¬í„´")
        return {}

    if SolarClient is None:
        print("   âŒ SolarClient í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ (Import ì‹¤íŒ¨).")
        return {}

    try:
        print("   ğŸ”Œ SolarClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í˜¸ì¶œ ì‹œë„...")
        client = SolarClient()

        # ì‹¤ì œ AI í˜¸ì¶œ
        result = client.parse_character(text)

        print(f"   âœ… [Solar ì‘ë‹µ ì„±ê³µ] íƒ€ì…: {type(result)}")
        print(f"   ğŸ‘‰ ì‘ë‹µ ë‚´ìš©(Keys): {list(result.keys()) if isinstance(result, dict) else 'Dictê°€ ì•„ë‹˜'}")
        # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ì¼ë¶€ë§Œ ì¶œë ¥
        print(f"   ğŸ‘‰ ì‘ë‹µ ë°ì´í„°(ì¼ë¶€): {str(result)[:100]}...")

        return result

    except Exception as e:
        print(f"   ğŸ”¥ [Solar í˜¸ì¶œ ì—ëŸ¬] {e}")
        import traceback
        traceback.print_exc() # ì—ëŸ¬ì˜ ìƒì„¸ ë‚´ìš©ì„ ë‹¤ ë³´ì—¬ì¤ë‹ˆë‹¤
        return {}
    finally:
        print("ğŸš€ [1ë‹¨ê³„] ì¢…ë£Œ")
        print("="*50 + "\n")

'''
def _extract_from_text(desc: str) -> Dict[str, Any]:
    desc = _remove_footnotes(desc or "")
    desc = _norm(desc)

    sections = _collect_sections(desc)

    age_gender = _clean_value(sections.get("age_gender", ""))
    job_status = _clean_value(sections.get("job_status", ""))

    core_traits_items = _split_bullets(sections.get("core_traits", ""))
    core_traits: Any = core_traits_items if core_traits_items else "none"

    personality = _parse_personality(sections.get("personality", ""))

    outer_goal = _clean_value(sections.get("outer_goal", ""))
    inner_goal = _clean_value(sections.get("inner_goal", ""))

    trauma_weakness = _clean_value(sections.get("trauma_weakness", ""))
    speech_habit = _clean_value(sections.get("speech_habit", ""))

    rel_items = _split_bullets(sections.get("relationships", ""))
    relationships: Any = rel_items if rel_items else "none"

    result = {
        "age_gender": age_gender,
        "job_status": job_status,
        "core_traits": core_traits,
        "personality": personality,
        "outer_goal": outer_goal,
        "inner_goal": inner_goal,
        "trauma_weakness": trauma_weakness,
        "speech_habit": speech_habit,
        "relationships": relationships,
    }

    # ì–‘ì‹ì´ ê±°ì˜ ì—†ìœ¼ë©´ ì„œìˆ í˜•ìœ¼ë¡œ ì±„ì›€
    empty_cnt = 0
    for k in ["age_gender", "job_status", "core_traits", "outer_goal", "inner_goal", "trauma_weakness", "speech_habit", "relationships"]:
        if result.get(k) in ("none", "", None):
            empty_cnt += 1

    if empty_cnt >= 6:
        result.update(
            {
                "age_gender": _extract_age_gender(desc),
                "job_status": _extract_job_status(desc),
                "core_traits": _extract_core_traits(desc),
                "outer_goal": _extract_goals(desc)[0],
                "inner_goal": _extract_goals(desc)[1],
                "trauma_weakness": _extract_trauma_weakness(desc),
                "speech_habit": _extract_speech_habit(desc),
                "relationships": _extract_relationships(desc),
                "personality": result.get("personality") or {"pros": "none", "cons": "none"},
            }
        )

    return result
'''

# -------------------------
# MERGE(ë³´ì™„/ìˆ˜ì •) ë¡œì§
# -------------------------
def _uniq_keep_order(items: List[str]) -> List[str]:
    out: List[str] = []
    for x in items:
        x = _norm(x)
        if not x or x == "none":
            continue
        if x not in out:
            out.append(x)
    return out


def _merge_comma_tags(old: str, new: str) -> str:
    old = _clean_value(old)
    new = _clean_value(new)
    if old == "none" and new == "none":
        return "none"
    if old == "none":
        return new
    if new == "none":
        return old

    old_parts = [p.strip() for p in old.split(",") if p.strip()]
    new_parts = [p.strip() for p in new.split(",") if p.strip()]
    merged = _uniq_keep_order(new_parts + old_parts)  # ìƒˆ ë‚´ìš©ì„ ìš°ì„ 
    return ", ".join(merged)


def _parse_age_gender_parts(s: str) -> Tuple[str, str]:
    s = _clean_value(s)
    if s == "none":
        return "", ""

    age = ""
    gender = ""
    m_age = re.search(r"(\d{1,3})\s*ì„¸(?!ê¸°)", s)
    if m_age:
        age = f"{m_age.group(1)}ì„¸"

    m_gender = re.search(r"(ë‚¨ì|ì—¬ì|ë‚¨ì„±|ì—¬ì„±)", s)
    if m_gender:
        g = m_gender.group(1)
        gender = "ë‚¨ì" if g in ("ë‚¨ì", "ë‚¨ì„±") else "ì—¬ì"

    return age, gender


def _merge_age_gender(old: str, new: str) -> str:
    old_age, old_gender = _parse_age_gender_parts(old)
    new_age, new_gender = _parse_age_gender_parts(new)

    age = new_age or old_age
    gender = new_gender or old_gender

    if not age and not gender:
        return "none"
    if age and gender:
        return f"{age} / {gender}"
    return age or gender


def _merge_list_field(old_val: Any, new_val: Any, *, max_items: int = 10) -> Any:
    # old/newê°€ "none" or list ë‘˜ ë‹¤ ì²˜ë¦¬
    old_list: List[str] = []
    new_list: List[str] = []

    if isinstance(old_val, list):
        old_list = old_val
    elif isinstance(old_val, str) and old_val != "none":
        old_list = [old_val]

    if isinstance(new_val, list):
        new_list = new_val
    elif isinstance(new_val, str) and new_val != "none":
        new_list = [new_val]

    merged = _uniq_keep_order(new_list + old_list)  # ìƒˆ ì •ë³´ ìš°ì„ 
    if not merged:
        return "none"
    return merged[:max_items]


def _merge_personality(old: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    old = old if isinstance(old, dict) else {"pros": "none", "cons": "none"}
    new = new if isinstance(new, dict) else {"pros": "none", "cons": "none"}

    def to_list(x: Any) -> List[str]:
        if isinstance(x, list):
            return x
        if isinstance(x, str) and x != "none":
            return [x]
        return []

    pros = _uniq_keep_order(to_list(new.get("pros")) + to_list(old.get("pros")))
    cons = _uniq_keep_order(to_list(new.get("cons")) + to_list(old.get("cons")))

    return {
        "pros": pros[:3] if pros else "none",
        "cons": cons[:3] if cons else "none",
    }


def _merge_character(old: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê·œì¹™:
    - newê°€ 'none'ì´ë©´ old ìœ ì§€
    - ë¬¸ìì—´ í•„ë“œ: newê°€ ì˜ë¯¸ ìˆìœ¼ë©´ êµì²´ (ë‹¨ age_genderëŠ” ë¶€ë¶„ ë³‘í•©)
    - ë¦¬ìŠ¤íŠ¸ í•„ë“œ(core_traits/relationships): í•©ì¹˜ê³  ì¤‘ë³µ ì œê±° (ìƒˆ ë‚´ìš© ìš°ì„ )
    - job_status: ì½¤ë§ˆ íƒœê·¸ ë³‘í•©
    - personality: pros/cons ë³‘í•©
    """
    merged = dict(old)

    merged["name"] = old.get("name") or new.get("name")

    merged["age_gender"] = _merge_age_gender(old.get("age_gender", "none"), new.get("age_gender", "none"))
    merged["job_status"] = _merge_comma_tags(old.get("job_status", "none"), new.get("job_status", "none"))

    merged["core_traits"] = _merge_list_field(old.get("core_traits", "none"), new.get("core_traits", "none"), max_items=10)
    merged["relationships"] = _merge_list_field(old.get("relationships", "none"), new.get("relationships", "none"), max_items=20)

    merged["personality"] = _merge_personality(old.get("personality", {}), new.get("personality", {}))

    for k in ["outer_goal", "inner_goal", "trauma_weakness", "speech_habit"]:
        nv = _clean_value(new.get(k, "none"))
        if nv != "none":
            merged[k] = nv
        else:
            merged[k] = _clean_value(old.get(k, "none"))

    # ë¹ˆ ê°’ ì •ë¦¬
    for k in ["age_gender", "job_status", "outer_goal", "inner_goal", "trauma_weakness", "speech_habit"]:
        merged[k] = _clean_value(merged.get(k, "none"))

    if merged.get("core_traits") == []:
        merged["core_traits"] = "none"
    if merged.get("relationships") == []:
        merged["relationships"] = "none"

    return merged


# -------------------------
# ê³µê°œ í•¨ìˆ˜
# -------------------------
def parse_character_with_name(name: str, features: str) -> Dict[str, Any]:
    print(f"ğŸ§© [2ë‹¨ê³„] parse_character_with_name í˜¸ì¶œë¨ (ì´ë¦„: {name})")

    nm = _clean_name(name)
    if not nm:
        raise ValueError("name is required")

    extracted = _extract_from_text(features or "")

    print(f"   ğŸ”„ [ë³‘í•© ì¤‘] ìµœì¢… JSON ì¡°ë¦½ ì‹œì‘...")

    # âœ… ì•ˆì „í•˜ê²Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ í—¬í¼ ë¡œì§ ì ìš©
    final_data = {
        "name": nm,
        "age_gender": extracted.get("age_gender") or "none",
        "job_status": extracted.get("job_status") or "none",
        # core_traitsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ê°•ì œ ë³€í™˜
        "core_traits": extracted.get("core_traits") if isinstance(extracted.get("core_traits"), list) else [],
        "personality": extracted.get("personality") if isinstance(extracted.get("personality"), dict) else {"pros": "none", "cons": "none"},
        "outer_goal": extracted.get("outer_goal") or "none",
        "inner_goal": extracted.get("inner_goal") or "none",
        "trauma_weakness": extracted.get("trauma_weakness") or "none",
        "speech_habit": extracted.get("speech_habit") or "none",
        # relationshipsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ê°•ì œ ë³€í™˜
        "relationships": extracted.get("relationships") if isinstance(extracted.get("relationships"), list) else [],
        # âœ… additional_settings ëˆ„ë½ ë°©ì§€ (ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¼ë„ ë„£ì–´ì¤Œ)
        "additional_settings": extracted.get("additional_settings") if isinstance(extracted.get("additional_settings"), dict) else {}
    }

    return final_data

def _clean_name(name: str) -> str:
    if not name: return ""
    return name.strip()


def upsert_character(name: str, features: str, *, db_path: str = DB_PATH) -> Dict[str, Any]:
    """
    âœ… ê°™ì€ ì´ë¦„ì´ë©´ overwriteê°€ ì•„ë‹ˆë¼ merge(ë³´ì™„/ìˆ˜ì •)
    """
    new_obj = parse_character_with_name(name, features)
    key = new_obj["name"]

    db = _read_json_safe(db_path)
    existed = key in db

    if existed and isinstance(db.get(key), dict):
        merged = _merge_character(db[key], new_obj)
        db[key] = merged
        saved = merged
        action = "merged"
    else:
        db[key] = new_obj
        saved = new_obj
        action = "inserted"

    _write_json(db_path, db)

    return {
        "status": "success",
        "action": action,
        "name": key,
        "saved": saved,
        "count": len(db),
        "db_path": db_path,
    }


__all__ = ["upsert_character", "parse_character_with_name", "DB_PATH"]