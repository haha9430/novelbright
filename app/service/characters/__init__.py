from __future__ import annotations

import json
import os
import re
from typing import Any, Dict, List, Tuple, Union

# ðŸ›‘ ì ˆëŒ€ ê²½ë¡œë¡œ ê³ ì •í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ ìœ„ì¹˜ë¥¼ ë§žì¶¥ë‹ˆë‹¤.
DB_PATH = "/app/app/data/characters.json"

from app.service.characters.solar_client import SolarClient


# =========================================================
# 1. íŒŒì¼ IO ë° ê¸°ì´ˆ ìœ í‹¸ (ì›ëž˜ ì½”ë“œ 100% ìœ ì§€)
# =========================================================
def _read_json_safe(path: str) -> Dict[str, Any]:
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data if isinstance(data, dict) else {}
    except Exception:
        return {}


def _write_json(path: str, data: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


def _norm(s: Any) -> str:
    if not isinstance(s, str):
        if isinstance(s, (dict, list)):
            return json.dumps(s, sort_keys=True, ensure_ascii=False)
        return str(s)
    return re.sub(r"\s+", " ", (s or "").strip())


def _clean_value(v: str) -> str:
    v = _norm(v)
    return v if v else "none"


def _strip_bullet(line: str) -> str:
    line = line.strip()
    line = re.sub(r"^[\-\*\â€¢]\s*", "", line)
    line = re.sub(r"^\d+[\.\)]\s*", "", line)
    return line.strip()


def _split_bullets(block: str) -> List[str]:
    if not block:
        return []
    lines = [x.strip() for x in block.splitlines() if x.strip()]
    out: List[str] = []
    for ln in lines:
        ln = _strip_bullet(ln)
        if ln:
            out.append(ln)
    return out


def _remove_footnotes(text: str) -> str:
    return re.sub(r"\[\d+\]", "", text)


def _clean_name(name: str) -> str:
    name = _remove_footnotes(name)
    name = re.sub(r"[\(\)ã€ã€‘\[\]]", "", name).strip()
    name = re.sub(r"\s+", " ", name).strip()
    return name


# =========================================================
# 2. ì •ê·œì‹ ê¸°ë°˜ ì„¹ì…˜ íŒŒì‹± (ì›ëž˜ ì½”ë“œ 100% ìœ ì§€)
# =========================================================
SECTION_ALIASES = {
    "age_gender": ["ë‚˜ì´(ìƒë…„ì›”ì¼, ì—†ìœ¼ë©´ ë‚˜ì´ë§Œ) /ì„±ë³„", "ë‚˜ì´/ì„±ë³„", "ë‚˜ì´", "ìƒë…„ì›”ì¼", "ì„±ë³„"],
    "job_status": ["ì§ì—…/ì‹ ë¶„", "ì§ì—…", "ì‹ ë¶„"],
    "core_traits": ["í•µì‹¬ íŠ¹ì§•", "í•µì‹¬íŠ¹ì§•", "íŠ¹ì§•"],
    "personality": ["ì„±ê²©"],
    "outer_goal": ["ì™¸ì  ëª©í‘œ"],
    "inner_goal": ["ë‚´ì  ëª©í‘œ"],
    "trauma_weakness": ["íŠ¸ë¼ìš°ë§ˆ/ì•½ì ", "íŠ¸ë¼ìš°ë§ˆ", "ì•½ì "],
    "speech_habit": ["ë§ë²„ë¦‡ì´ë‚˜ ìŠµê´€", "ë§ë²„ë¦‡", "ìŠµê´€"],
    "relationships": ["ë‹¤ë¥¸ ì£¼ìš” ì¸ë¬¼ê³¼ì˜ ê´€ê³„", "ì£¼ìš” ì¸ë¬¼ê³¼ì˜ ê´€ê³„", "ê´€ê³„"],
}


def _detect_section(line: str) -> Tuple[str | None, str]:
    s = line.strip()
    s_no_paren = re.sub(r"\(.*?\)", "", s).strip()

    for key, aliases in SECTION_ALIASES.items():
        for a in aliases:
            if s_no_paren.startswith(a):
                if ":" in s:
                    return key, s.split(":", 1)[1].strip()
                rest = s_no_paren[len(a):].strip()
                rest = rest.lstrip("-").strip()
                return key, rest
    return None, ""


def _collect_sections(text: str) -> Dict[str, str]:
    lines = [ln.rstrip() for ln in (text or "").splitlines()]
    lines = [ln for ln in lines if ln.strip()]

    buckets: Dict[str, List[str]] = {k: [] for k in SECTION_ALIASES.keys()}
    current: str | None = None

    for ln in lines:
        key, inline = _detect_section(ln)
        if key:
            current = key
            if inline:
                buckets[current].append(inline)
            continue
        if current:
            buckets[current].append(ln.strip())

    return {k: "\n".join(v).strip() for k, v in buckets.items()}


def _parse_personality(block: str) -> Dict[str, Any]:
    if not block:
        return {"pros": "none", "cons": "none"}

    lines = [x.strip() for x in block.splitlines() if x.strip()]
    mode = None
    pros: List[str] = []
    cons: List[str] = []
    misc: List[str] = []

    for ln in lines:
        s = _strip_bullet(ln)
        if not s: continue

        if s.startswith("ìž¥ì "):
            mode = "pros"
            after = s.split(":", 1)[1].strip() if ":" in s else s.replace("ìž¥ì ", "", 1).strip()
            if after: pros.extend(_split_bullets(after))
            continue

        if s.startswith("ë‹¨ì "):
            mode = "cons"
            after = s.split(":", 1)[1].strip() if ":" in s else s.replace("ë‹¨ì ", "", 1).strip()
            if after: cons.extend(_split_bullets(after))
            continue

        if mode == "pros":
            pros.append(s)
        elif mode == "cons":
            cons.append(s)
        else:
            misc.append(s)

    if (not pros and not cons) and misc:
        items = _split_bullets("\n".join(misc))
        pros = items[:3]
        cons = items[3:6]

    return {"pros": pros[:3] if pros else "none", "cons": cons[:3] if cons else "none"}


# =========================================================
# 3. íœ´ë¦¬ìŠ¤í‹±(í‚¤ì›Œë“œ) ì¶”ì¶œ ë¡œì§ (ì›ëž˜ ì½”ë“œ 100% ìœ ì§€)
# =========================================================
def _extract_job_status(text: str) -> str:
    candidates: List[str] = []
    keywords = [
        "ì™¸ìƒì™¸ê³¼ì˜", "ì™¸ê³¼ì˜", "ì¼ë°˜ì™¸ê³¼", "ì˜ì‚¬", "ì „ìž„ ì¡°êµìˆ˜", "ì¡°êµìˆ˜", "êµìˆ˜", "êµ°ì˜ê´€",
        "ì˜ëŒ€", "UCL", "ë©´í—ˆ", "ëŸ°ë˜ëŒ€ êµìˆ˜",
    ]
    for kw in keywords:
        if kw in text: candidates.append(kw)

    uniq: List[str] = []
    for x in candidates:
        if x not in uniq: uniq.append(x)

    if not uniq: return "none"
    return ", ".join(uniq[:5])


def _extract_trauma_weakness(text: str) -> str:
    if "ë‡Œì¢…ì–‘" in text and "íŒì •" in text: return "ë‡Œì¢…ì–‘ íŒì • ê²½í—˜"
    if "ê²°í•µ" in text: return "ì „ìŸ ì¤‘ ê²°í•µìœ¼ë¡œ ì£½ì„ ë»”í•¨"
    if "ì£½ì„ ë»”" in text: return "ìƒëª… ìœ„í˜‘ ê²½í—˜"
    return "none"


def _extract_speech_habit(text: str) -> str:
    if "ì¡°ì„  ì˜í•™" in text and ("ê±°ì§“ë§" in text or "êµ¬ë¼" in text):
        return "í˜„ëŒ€ì§€ì‹ ì¶œì²˜ë¥¼ 'ì¡°ì„  ì˜í•™'ì´ë¼ê³  ë‘˜ëŸ¬ëŒ€ëŠ” ìŠµê´€"
    return "none"


def _extract_core_traits(text: str) -> List[str] | str:
    traits: List[str] = []
    if "21ì„¸ê¸°" in text and "19ì„¸ê¸°" in text and ("ë‹¤ì‹œ íƒœì–´ë‚œë‹¤" in text or "í™˜ìƒ" in text):
        traits.append("21ì„¸ê¸° í•œêµ­ ì¶œì‹ ìœ¼ë¡œ 19ì„¸ê¸° ì˜êµ­ì—ì„œ ì¡°ì„ ì¸ìœ¼ë¡œ ë‹¤ì‹œ íƒœì–´ë‚¨")
    if "ì™¸ìƒì™¸ê³¼" in text or "ì¼ë°˜ì™¸ê³¼" in text or "ì™¸ê³¼ì˜" in text:
        traits.append("í˜„ëŒ€ ì™¸ê³¼(ì¼ë°˜/ì™¸ìƒ) ì „ë¬¸ ì§€ì‹ê³¼ ìˆ˜ìˆ  ì‹¤ë ¥ ë³´ìœ ")
    if "ì¡°ì„  ì˜í•™" in text and ("ê±°ì§“ë§" in text or "êµ¬ë¼" in text):
        traits.append("í˜„ëŒ€ ì§€ì‹ ì‚¬ìš© ì‹œ 'ì¡°ì„  ì˜í•™ì—ì„œ ë°°ì› ë‹¤'ê³  ìœ„ìž¥")
    if "êµ°ì˜ê´€" in text or "ì°¸ì „" in text or "ì „ìŸ" in text:
        traits.append("ì „ìŸì— êµ°ì˜ê´€ìœ¼ë¡œ ì°¸ì—¬í•˜ë©° ì¹˜ë£Œ/ìž„ìƒ ê²½í—˜ ì¶•ì ")

    uniq: List[str] = []
    for t in traits:
        if t not in uniq: uniq.append(t)
    return uniq if uniq else "none"


def _extract_relationships(text: str) -> List[str] | str:
    rels: List[str] = []
    if "ë¦¬ìŠ¤í„´" in text:
        if "ì¶”ì²œ" in text:
            rels.append("ë¡œë²„íŠ¸ ë¦¬ìŠ¤í„´: ê°•ë ¥ ì¶”ì²œ/ë™ë£Œ(í˜¹ì€ ìŠ¤ìŠ¹ê¸‰ ì¸ë§¥)")
        else:
            rels.append("ë¦¬ìŠ¤í„´: ë™ë£Œ/í˜‘ì—… ì¸ë¬¼(ë³¸ë¬¸ ê¸°ë°˜)")
    if "ë‚˜ì´íŒ…ê²Œì¼" in text: rels.append("ë‚˜ì´íŒ…ê²Œì¼: í¬ë¦¼ ì „ìŸ ì•¼ì „ë³‘ì› ì²´ê³„ êµ¬ì¶• í˜‘ì—…")
    if "í›„ì›" in text or "ì§€ì—­ ìœ ì§€" in text: rels.append("ì§€ì—­ ìœ ì§€: ì¸ì¢…ì°¨ë³„ ì‹œëŒ€ì— í›„ì›ìž")

    uniq: List[str] = []
    for r in rels:
        if r not in uniq: uniq.append(r)
    return uniq if uniq else "none"


def _extract_goals(text: str) -> Tuple[str, str]:
    outer = "none"
    inner = "none"
    if "ë§ì—°ìžì‹¤" in text or "ë‡Œì¢…ì–‘" in text:
        inner = "ì£½ìŒ/ì§ˆë³‘ ê²½í—˜ ì´í›„ ìƒì¡´ê³¼ ì„±ìž¥ì— ì§‘ì°©í•˜ê²Œ ë¨(ì„œìˆ  ê¸°ë°˜)"
    return outer, inner


def _extract_age_gender(text: str) -> str:
    age = ""
    gender = ""
    m_age = re.search(r"(\d{1,3})\s*ì„¸(?!ê¸°)", text)
    if m_age: age = f"{m_age.group(1)}ì„¸"
    m_gender = re.search(r"(ë‚¨ìž|ì—¬ìž|ë‚¨ì„±|ì—¬ì„±)", text)
    if m_gender:
        g = m_gender.group(1)
        gender = "ë‚¨ìž" if g in ("ë‚¨ìž", "ë‚¨ì„±") else "ì—¬ìž"
    if not age and not gender: return "none"
    if age and gender: return f"{age} / {gender}"
    return age or gender


# =========================================================
# 4. ë°ì´í„° ì¶”ì¶œ í†µí•© (AI ìš°ì„  -> Fallback)
# =========================================================
def _extract_from_text(text: str) -> Any:
    print("\n" + "=" * 50)
    print("ðŸš€ [1ë‹¨ê³„] _extract_from_text ì‹œìž‘")

    if not text or not text.strip():
        return {}

    if SolarClient is not None:
        try:
            print("   ðŸ”Œ SolarClient í˜¸ì¶œ ì¤‘...")
            client = SolarClient()
            result = client.parse_character(text)
            if result:
                print(f"   âœ… [Solar ì‘ë‹µ ì„±ê³µ] íƒ€ìž…: {type(result)}")
                return result
        except Exception as e:
            print(f"   ðŸ”¥ [Solar í˜¸ì¶œ ì—ëŸ¬] {e}")

    print("   âš ï¸ Solar ì‹¤íŒ¨/ë¯¸ì„¤ì • -> ì •ê·œì‹ Fallback ì‹¤í–‰")
    sections = _collect_sections(text)

    h_age_gender = _extract_age_gender(text)
    h_job = _extract_job_status(text)
    h_traits = _extract_core_traits(text)
    h_rels = _extract_relationships(text)
    _, h_inner = _extract_goals(text)
    h_trauma = _extract_trauma_weakness(text)
    h_habit = _extract_speech_habit(text)

    fallback_result = {
        "name": "Unknown",
        "age_gender": _clean_value(sections.get("age_gender")) if sections.get("age_gender") else h_age_gender,
        "job_status": _clean_value(sections.get("job_status")) if sections.get("job_status") else h_job,
        "core_traits": _split_bullets(sections.get("core_traits", "")) or h_traits,
        "personality": _parse_personality(sections.get("personality", "")),
        "relationships": _split_bullets(sections.get("relationships", "")) or h_rels,
        "outer_goal": _clean_value(sections.get("outer_goal", "none")),
        "inner_goal": _clean_value(sections.get("inner_goal")) if sections.get("inner_goal") else h_inner,
        "trauma_weakness": _clean_value(sections.get("trauma_weakness")) if sections.get(
            "trauma_weakness") else h_trauma,
        "speech_habit": _clean_value(sections.get("speech_habit")) if sections.get("speech_habit") else h_habit,
    }

    return fallback_result


# =========================================================
# 5. MERGE(ë³´ì™„/ìˆ˜ì •) ë¡œì§ (ì›ëž˜ ì½”ë“œ 100% ìœ ì§€)
# =========================================================
def _uniq_keep_order(items: List[str]) -> List[str]:
    out: List[str] = []
    for x in items:
        x = _norm(x)
        if not x or x == "none": continue
        if x not in out: out.append(x)
    return out


def _merge_comma_tags(old: str, new: str) -> str:
    old = _clean_value(old)
    new = _clean_value(new)
    if old == "none": return new
    if new == "none": return old
    old_parts = [p.strip() for p in old.split(",") if p.strip()]
    new_parts = [p.strip() for p in new.split(",") if p.strip()]
    return ", ".join(_uniq_keep_order(new_parts + old_parts))


def _merge_age_gender(old: str, new: str) -> str:
    return new if new and new != "none" else old


def _merge_list_field(old_val: Any, new_val: Any, *, max_items: int = 10) -> Any:
    old_list = old_val if isinstance(old_val, list) else ([old_val] if old_val and old_val != "none" else [])
    new_list = new_val if isinstance(new_val, list) else ([new_val] if new_val and new_val != "none" else [])
    merged = _uniq_keep_order(new_list + old_list)
    return merged[:max_items] if merged else "none"


def _merge_personality(old: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    old = old if isinstance(old, dict) else {"pros": "none", "cons": "none"}
    new = new if isinstance(new, dict) else {"pros": "none", "cons": "none"}
    def to_l(v): return v if isinstance(v, list) else ([v] if v and v != "none" else [])
    pros = _uniq_keep_order(to_l(new.get("pros")) + to_l(old.get("pros")))
    cons = _uniq_keep_order(to_l(new.get("cons")) + to_l(old.get("cons")))
    return {"pros": pros[:3] if pros else "none", "cons": cons[:3] if cons else "none"}


def _merge_character(old: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    merged = dict(old)
    merged["name"] = old.get("name") or new.get("name")
    merged["age_gender"] = _merge_age_gender(old.get("age_gender", "none"), new.get("age_gender", "none"))
    merged["job_status"] = _merge_comma_tags(old.get("job_status", "none"), new.get("job_status", "none"))
    merged["core_traits"] = _merge_list_field(old.get("core_traits"), new.get("core_traits"), max_items=10)
    merged["relationships"] = _merge_list_field(old.get("relationships"), new.get("relationships"), max_items=20)
    merged["personality"] = _merge_personality(old.get("personality", {}), new.get("personality", {}))
    for k in ["outer_goal", "inner_goal", "trauma_weakness", "speech_habit"]:
        nv = _clean_value(new.get(k, "none"))
        merged[k] = nv if nv != "none" else _clean_value(old.get(k, "none"))
    return merged


# =========================================================
# 6. ê³µê°œ í•¨ìˆ˜ & Ingest Entry Point (ì ˆëŒ€ ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ)
# =========================================================
def summarize_character_info(text: str) -> Dict[str, Any]:
    print("ðŸš€ [Character Module] ë¶„ì„ ìš”ì²­ ìˆ˜ì‹ ...")
    extracted = _extract_from_text(text)
    targets = []
    if isinstance(extracted, list): targets = extracted
    elif isinstance(extracted, dict) and extracted: targets = [extracted]

    if not targets:
        print("   âš ï¸ ìºë¦­í„° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {"status": "error", "message": "No character detected"}

    print(f"   âœ… ê°ì§€ëœ ìºë¦­í„° ìˆ˜: {len(targets)}ëª…")
    saved_names = []
    for char_info in targets:
        if not isinstance(char_info, dict): continue
        raw_name = char_info.get("name")
        if not raw_name or raw_name in ["none", "Unknown", ""]: continue
        key = _clean_name(raw_name)
        char_info["name"] = key
        upsert_character(key, char_info)
        saved_names.append(key)
        print(f"      - ì €ìž¥ ì™„ë£Œ: {key}")

    return {"status": "success", "names": saved_names, "count": len(saved_names)}


def upsert_character(name: str, features: Union[str, Dict[str, Any]], *, db_path: str = DB_PATH) -> Dict[str, Any]:
    key = _clean_name(name)
    if isinstance(features, dict):
        new_obj = features
        new_obj["name"] = key
    else:
        extracted = _extract_from_text(features)
        if isinstance(extracted, list) and extracted: new_obj = extracted[0]
        elif isinstance(extracted, dict): new_obj = extracted
        else: new_obj = {"name": key}

    db = _read_json_safe(db_path)
    if key in db:
        db[key] = _merge_character(db[key], new_obj)
        action = "merged"
    else:
        db[key] = new_obj
        action = "inserted"
    _write_json(db_path, db)
    return {"status": "success", "action": action, "name": key}

def parse_character_with_name(name: str, features: str) -> Dict[str, Any]:
    return {"name": name, "raw_text": features}

__all__ = ["upsert_character", "summarize_character_info", "DB_PATH"]