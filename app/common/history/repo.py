from __future__ import annotations

from datetime import datetime, timezone, timedelta
from typing import Any, Dict, List, Optional
import difflib  # <--- [ì¤‘ìš”] ì´ ì¤„ì´ ê¼­ ì¶”ê°€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤!
import json
import os

from .schema import HistoricalEntity, RelatedEntity
from .storage import read_json, write_json_atomic
from app.common.history.vector_store import vector_store

# í•œêµ­ ì‹œê°„(KST) ì„¤ì •
KST = timezone(timedelta(hours=9))

def _now_iso() -> str:
    return datetime.now(KST).isoformat(timespec="seconds")

def _default_db() -> Dict[str, Any]:
    return {
        "meta": {"version": 1, "updated_at": _now_iso()},
        "entities": []
    }

def _next_id(existing_ids: List[str]) -> str:
    nums = []
    for eid in existing_ids:
        if eid.startswith("hist_"):
            tail = eid.replace("hist_", "")
            if tail.isdigit():
                nums.append(int(tail))
    n = (max(nums) + 1) if nums else 1
    return f"hist_{n:04d}"

def init_db(db_path: str) -> None:
    data = read_json(db_path)
    if not data:
        write_json_atomic(db_path, _default_db())

def _load(db_path: str) -> Dict[str, Any]:
    data = read_json(db_path)
    if not data:
        data = _default_db()
        write_json_atomic(db_path, data)
    if "entities" not in data:
        data["entities"] = []
    return data

def _save(db_path: str, data: Dict[str, Any]) -> None:
    data["meta"]["updated_at"] = _now_iso()
    write_json_atomic(db_path, data)

# ---------------------------------------------------------
# [Helper] ë²¡í„° DB ë™ê¸°í™”
# ---------------------------------------------------------
def force_sync_vector_db(db_path: str):
    _sync_vector_db(db_path)

def _sync_vector_db(db_path: str):
    """
    í˜„ì¬ JSON DBì˜ ë‚´ìš©ì„ ì½ì–´ì™€ ë²¡í„° DB(Chroma)ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.
    Create/Update/Delete ì§í›„ì— í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    try:
        current_data = list_entities(db_path)
        vector_store.sync_from_json(current_data)
        print(f"âœ… [Repo] ë²¡í„° DB ë™ê¸°í™” ì™„ë£Œ (ì´ {len(current_data)}ê±´)")
    except Exception as e:
        print(f"âš ï¸ [Repo] ë²¡í„° DB ë™ê¸°í™” ì‹¤íŒ¨: {e}")

# ---------------------------------------------------------
# [Read] ì¡°íšŒ ë° ê²€ìƒ‰ ê¸°ëŠ¥
# ---------------------------------------------------------

def list_entities(db_path: str) -> List[Dict[str, Any]]:
    data = _load(db_path)
    return list(data["entities"])

def get_entity(db_path: str, entity_id: str) -> Optional[Dict[str, Any]]:
    data = _load(db_path)
    for e in data["entities"]:
        if e.get("id") == entity_id:
            return e
    return None

def normalize_string(s: str) -> str:
    """ë¹„êµë¥¼ ìœ„í•´ íŠ¹ìˆ˜ë¬¸ìì™€ ê³µë°±ì„ ì œê±°í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    special_chars = "Â·,.-_ []{}()"
    result = str(s).lower()
    for char in special_chars:
        result = result.replace(char, "")
    return result

def find_id_by_name(db_path: str, name: str) -> Optional[str]:
    """
    ì´ë¦„ìœ¼ë¡œ ID ì°¾ê¸° (4ë‹¨ê³„ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜)
    1. ì •í™• ì¼ì¹˜ -> 2. ì •ê·œí™” ì¼ì¹˜ -> 3. í¬í•¨ ê´€ê³„ -> 4. ìˆœì„œ í¬í•¨(Subsequence) -> 5. ìœ ì‚¬ë„
    """
    target_raw = (name or "").strip()
    if not target_raw:
        return None

    data = _load(db_path)
    entities = data["entities"]

    # 1. [100%] ì •í™•í•œ ì¼ì¹˜
    for e in entities:
        if e.get("name") == target_raw:
            return e.get("id")

    # ì •ê·œí™” (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°)
    target_norm = normalize_string(target_raw)

    # 2. [90%] ì •ê·œí™” ì¼ì¹˜ ("í™ ë¦‰" == "í™ë¦‰")
    for e in entities:
        if normalize_string(e.get("name")) == target_norm:
            return e.get("id")

    # 3. [80%] í¬í•¨ ê´€ê³„ ("í™ë¦‰" in "í™ë¦‰Â·ìœ ë¦‰")
    for e in entities:
        e_norm = normalize_string(e.get("name"))
        if target_norm in e_norm or e_norm in target_norm:
            return e.get("id")

    # 4. [70%] ìˆœì„œëŒ€ë¡œ ê¸€ìê°€ í¬í•¨ëœ ê²½ìš° (í™ìœ ë¦‰ -> í™ë¦‰Â·ìœ ë¦‰)
    for e in entities:
        e_norm = normalize_string(e.get("name"))
        it = iter(e_norm)
        if all(char in it for char in target_norm):
            return e.get("id")

    # 5. [ìµœí›„ì˜ ìˆ˜ë‹¨] ìœ ì‚¬ë„ ê²€ìƒ‰ (difflib)
    entity_names = [e.get("name", "") for e in entities]
    matches = difflib.get_close_matches(target_raw, entity_names, n=1, cutoff=0.4)
    if matches:
        best_match = matches[0]
        for e in entities:
            if e.get("name") == best_match:
                return e.get("id")

    return None

def search_by_keyword(db_path: str, keyword: str) -> List[Dict[str, Any]]:
    data = _load(db_path)
    results = []
    keyword = keyword.lower().strip()

    for e in data["entities"]:
        searchable_text = f"{e.get('name')} {' '.join(e.get('tags', []))} {e.get('summary')} {e.get('era')}".lower()
        if keyword in searchable_text:
            results.append(e)
    return results


# ---------------------------------------------------------
# [Write] ë³€ê²½ ê¸°ëŠ¥ (Create, Update, Delete)
# ---------------------------------------------------------

def create_entity(db_path: str, payload: Dict[str, Any], auto_sync: bool = True) -> Dict[str, Any]:
    data = _load(db_path)
    existing_ids = [e.get("id", "") for e in data["entities"]]

    # ID ìƒì„±
    eid = payload.get("id") or _next_id(existing_ids)
    if any(e.get("id") == eid for e in data["entities"]):
        raise ValueError(f"Entity ID already exists: {eid}")

    now = _now_iso()
    payload = dict(payload)
    payload["id"] = eid
    payload.setdefault("created_at", now)
    payload.setdefault("updated_at", now)

    # ê°ì²´ ê²€ì¦ ë° ë³€í™˜
    try:
        entity_obj = HistoricalEntity.from_dict(payload)
        final_data = entity_obj.to_dict()
    except Exception as e:
        raise ValueError(f"Invalid entity data: {e}")

    # 1. JSON DB ì €ì¥
    data["entities"].append(final_data)
    _save(db_path, data)

    # ğŸ‘‡ auto_syncê°€ Trueì¼ ë•Œë§Œ ë™ê¸°í™” ìˆ˜í–‰
    if auto_sync:
        _sync_vector_db(db_path)

    return final_data

def update_entity(db_path: str, entity_id: str, patch: Dict[str, Any], auto_sync: bool = True) -> Dict[str, Any]:
    data = _load(db_path)
    for i, e in enumerate(data["entities"]):
        if e.get("id") == entity_id:
            updated = dict(e)
            updated.update(patch)
            updated["id"] = entity_id # ID ë¶ˆë³€
            updated["updated_at"] = _now_iso()

            if "related_entities" in patch:
                rels = patch["related_entities"]
                updated["related_entities"] = [
                    RelatedEntity(**r).to_dict() if isinstance(r, dict) else r
                    for r in rels
                ]

            # 1. JSON DB ì €ì¥
            data["entities"][i] = updated
            _save(db_path, data)

            # ğŸ‘‡ auto_syncê°€ Trueì¼ ë•Œë§Œ ë™ê¸°í™” ìˆ˜í–‰
            if auto_sync:
                _sync_vector_db(db_path)

            return updated

    raise KeyError(f"Entity not found: {entity_id}")

def delete_entity(db_path: str, entity_id: str, auto_sync: bool = True) -> bool:
    data = _load(db_path)
    before_count = len(data["entities"])

    # ë³¸ì²´ ì‚­ì œ
    data["entities"] = [e for e in data["entities"] if e.get("id") != entity_id]

    if len(data["entities"]) == before_count:
        return False # ì‚­ì œëœ ê²Œ ì—†ìŒ

    # ê´€ê³„ ë°ì´í„° ì •ë¦¬ (Cascade ìœ ì‚¬ íš¨ê³¼)
    for e in data["entities"]:
        rels = e.get("related_entities", [])
        if not rels:
            continue
        new_rels = [r for r in rels if r.get("target_id") != entity_id]
        if len(new_rels) != len(rels):
            e["related_entities"] = new_rels
            e["updated_at"] = _now_iso()

    # 1. JSON DB ì €ì¥
    _save(db_path, data)

    # ğŸ‘‡ auto_syncê°€ Trueì¼ ë•Œë§Œ ë™ê¸°í™” ìˆ˜í–‰
    if auto_sync:
        _sync_vector_db(db_path)

    return True

def upsert_material(db_path: str, new_material_data: dict):
    """
    IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ êµì²´(Update), ì—†ìœ¼ë©´ ì¶”ê°€(Insert)
    """
    # 1. íŒŒì¼ ë¡œë“œ (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìƒì„±)
    # ---------------------------------------------------------
    try:
        with open(db_path, "r", encoding="utf-8") as f:
            all_materials = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        all_materials = []

    # 2. íƒìƒ‰: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ìë£Œì¸ì§€ IDë¡œ í™•ì¸
    # ---------------------------------------------------------
    target_idx = -1
    for i, item in enumerate(all_materials):
        if item["id"] == new_material_data["id"]:
            target_idx = i
            break

    # 3. ë°ì´í„° ë¬´ê²°ì„± ë³´ì™„
    # ---------------------------------------------------------
    # ë§Œì•½ ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ë°, ìƒˆ ë°ì´í„°ì— 'linked_entity_ids'ê°€ ëˆ„ë½ë˜ì—ˆë‹¤ë©´?
    # ì‹¤ìˆ˜ë¡œ ë§í¬ ì •ë³´ê°€ ë‚ ì•„ê°€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ê¸°ì¡´ ê°’ì„ ìœ ì§€í•˜ëŠ” ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    if target_idx >= 0:
        existing_data = all_materials[target_idx]

        # ìƒˆ ë°ì´í„°ì— linked_entity_idsê°€ ì—†ìœ¼ë©´, ê¸°ì¡´ ê±¸ ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.
        if "linked_entity_ids" not in new_material_data:
            new_material_data["linked_entity_ids"] = existing_data.get("linked_entity_ids", [])

        # created_atë„ ë³´í†µì€ ì²˜ìŒì— ë§Œë“  ë‚ ì§œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        if "created_at" not in new_material_data:
            new_material_data["created_at"] = existing_data.get("created_at")

    # 4. ì €ì¥ ì‹¤í–‰ (Upsert)
    # ---------------------------------------------------------
    if target_idx >= 0:
        # [Update] êµì²´
        all_materials[target_idx] = new_material_data
        action = "updated"
    else:
        # [Insert] ì¶”ê°€
        all_materials.append(new_material_data)
        action = "created"

    # 5. íŒŒì¼ ì“°ê¸°
    # ---------------------------------------------------------
    with open(db_path, "w", encoding="utf-8") as f:
        # ensure_ascii=False: í•œê¸€ ê¹¨ì§ ë°©ì§€
        # indent=4: ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ ì¤„ë°”ê¿ˆ
        json.dump(all_materials, f, ensure_ascii=False, indent=4)

    print(f"ğŸ’¾ Material {action}: {new_material_data.get('title', 'No Title')}")
    return new_material_data

def get_material(db_path: str, material_id: str) -> Optional[Dict[str, Any]]:
    """
        [ê¸°ëŠ¥] material_db.jsonì—ì„œ íŠ¹ì • IDì˜ ìë£Œë¥¼ ì°¾ì•„ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
        [ë¦¬í„´] ì°¾ìœ¼ë©´ dict ê°ì²´, ì—†ìœ¼ë©´ None
    """
    # 1. íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸ (ì—†ìœ¼ë©´ ì°¾ì„ ê²ƒë„ ì—†ìŒ)
    if not os.path.exists(db_path):
        return None

    try:
        # 2. íŒŒì¼ ì½ê¸°
        with open(db_path, "r", encoding="utf-8") as f:
            materials = json.load(f)

        # 3. ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ID ë¹„êµ (Linear Search)
        for item in materials:
            if item.get("id") == material_id:
                return item

        # 4. ëê¹Œì§€ ëŒì•˜ëŠ”ë° ì—†ìœ¼ë©´ None ë°˜í™˜
        return None

    except json.JSONDecodeError:
        # íŒŒì¼ì€ ìˆëŠ”ë° ë‚´ìš©ì´ ê¹¨ì ¸ìˆê±°ë‚˜ ë¹ˆ íŒŒì¼ì¼ ê²½ìš°
        return None
    except Exception as e:
        print(f"âŒ Material ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def delete_material(db_path: str, material_id: str) -> bool:
    """
    [ê¸°ëŠ¥] material_db.jsonì—ì„œ í•´ë‹¹ IDì˜ ìë£Œë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(db_path):
        return False

    try:
        # 1. ë¡œë“œ
        with open(db_path, "r", encoding="utf-8") as f:
            materials = json.load(f)

        # 2. í•„í„°ë§ (ì‚­ì œí•  IDë¥¼ ëº€ ë‚˜ë¨¸ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±)
        # ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ìœ¼ë¡œ í•´ë‹¹ IDê°€ ì•„ë‹Œ ê²ƒë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        new_materials = [m for m in materials if m["id"] != material_id]

        # ì‚­ì œëœ ê²Œ ì—†ìœ¼ë©´(ê¸¸ì´ê°€ ê°™ìœ¼ë©´) False
        if len(materials) == len(new_materials):
            return False

        # 3. ì €ì¥
        with open(db_path, "w", encoding="utf-8") as f:
            json.dump(new_materials, f, ensure_ascii=False, indent=4)

        print(f"ğŸ—‘ï¸ Material ì‚­ì œ ì™„ë£Œ: {material_id}")
        return True

    except Exception as e:
        print(f"âŒ Material ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        return False